{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b07c8ef",
   "metadata": {},
   "source": [
    "### üìÅ Available LoRa Models\n",
    "\n",
    "| Model Size | Motion Type | LoRa Name | Description |\n",
    "|-------|-------------|-----------|-------------|\n",
    "| Lite, Pro | Object Rotation | `Microwave-right` | Rotates object ~360¬∞ to the right over 5 seconds |\n",
    "| Lite, Pro | Object Rotation | `Microwave-left` | Rotates object ~360¬∞ to the left over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-right` | Camera arcs ~360¬∞ around object to the right over 5 seconds |\n",
    "| Lite, Pro | Camera Movement | `Arc-left` | Camera arcs ~360¬∞ around object to the left over 5 seconds |\n",
    "| Lite | Camera Movement | `Dolly-in` | Camera moves forward toward subject |\n",
    "| Lite | Camera Movement | `Dolly-out` | Camera moves backward from subject |\n",
    "| Lite | Camera Movement | `Truck-right` | Camera tracks horizontally to the right |\n",
    "| Lite | Camera Movement | `Truck-left` | Camera tracks horizontally to the left |\n",
    "\n",
    "<br>\n",
    "\n",
    ">  Note:\n",
    "> 1. For optimal performance, select an appropriate LoRa for the **t2v** (text-to-video) or **i2v** (image-to-video) modality.  \n",
    ">    We named our LoRas using the template: `kandinskylab/Kandinsky-5.0-{Modality}-{Model_Size}-LoRa-{LoRa_Name}` where `Modality` is either `I2V` or `T2V`.\n",
    "> 2. Additional camera movements in the **Pro** model can be achieved directly via the prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135f0af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "import torch\n",
    "from huggingface_hub import snapshot_download\n",
    "from kandinsky import get_video_pipeline\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc5af47",
   "metadata": {},
   "source": [
    "### Load pipe \n",
    "first, ensure that you have downloaded the models using `download_models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5198a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = get_video_pipeline(\n",
    "    device_map={\"dit\": \"cuda:0\", \"vae\": \"cuda:0\", \"text_embedder\": \"cuda:0\"},\n",
    "    conf_path=\"./configs/k5_lite_t2v_5s_sft_sd.yaml\",\n",
    "    mode='t2v',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673000c4",
   "metadata": {},
   "source": [
    "#### Download LoRa adapter from HuggingFaceü§ó:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = './weights'\n",
    "lora_name = 'Microwave-right'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-T2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484cf6ac",
   "metadata": {},
   "source": [
    "Load the adapter into the pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08230234",
   "metadata": {},
   "source": [
    "Note: The trigger words we use are stored in the LoRA safetensors metadata. They are automatically concatenated with prompts during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b4a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.peft_triggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6725a88f",
   "metadata": {},
   "source": [
    "Generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e2a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './outputs/loras/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d262fc",
   "metadata": {},
   "source": [
    "Download another adapter and switch to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd1fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_name = 'Microwave-left'\n",
    "repo_id = f\"kandinskylab/Kandinsky-5.0-T2V-Lite-LoRa-{lora_name}\"\n",
    "adapter_path = snapshot_download(\n",
    "    repo_id=repo_id,\n",
    "    local_dir=os.path.join(cache_dir, repo_id),\n",
    "    token=None\n",
    ")\n",
    "pipe.load_adapter(\n",
    "    adapter_config=os.path.join(cache_dir, repo_id, \"config_lora.json\"),\n",
    "    adapter_path= os.path.join(cache_dir, repo_id, \"lora.safetensors\"),\n",
    "    adapter_name=lora_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bf5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{lora_name}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b2ca3",
   "metadata": {},
   "source": [
    "Switch to the previous LoRa adapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_lora_name = 'Microwave-right'\n",
    "pipe.set_adapter(prev_lora_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b373622",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f't2v_lite_{prev_lora_name}_v2.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f't2v_lite_{prev_lora_name}_v2.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154ebee7",
   "metadata": {},
   "source": [
    "Disable all adapters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53524ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.disable_adapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b460d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\n",
    "    \"a cat in a red hat\",\n",
    "    time_length=5,\n",
    "    width=768,\n",
    "    height=512,\n",
    "    save_path=os.path.join(save_dir, f'default.mp4'),\n",
    "    seed=1234,\n",
    ")\n",
    "Video(os.path.join(save_dir, f'default.mp4'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
