{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3d5bb-3d04-4d11-aba6-043fc5667abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from kandinsky.utils import set_hf_token\n",
    "from PIL import Image\n",
    "\n",
    "# NOTE: specify your HF token or download all the required checkpoints in advance;\n",
    "# T2I / I2I require FLUX.1-dev VAE, which is a closed repo\n",
    "HF_TOKEN = None\n",
    "set_hf_token(HF_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcf5ed-f813-47e1-ade6-3f655d35d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kandinsky import get_image_pipeline\n",
    "pipe = get_image_pipeline(\n",
    "    resolution=1024, offload=True, mode='t2i',\n",
    "    device_map={\"dit\": \"cuda:0\", \"vae\": \"cuda:0\", \"text_embedder\": \"cuda:0\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc4ef9-0492-41a1-8133-c7e10a894d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a cat in a red hat. white text 'sweet' writen on a hat\"\n",
    "out = pipe(prompt,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbd345-9ae0-48a6-bdb9-24f4c63d48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].resize((368,368))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34173d7e",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "\n",
    "You can also use your own LoRa with simple code modification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32312e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.load_adapter(\n",
    "    adapter_config=\"config.json\",\n",
    "    adapter_path=\"lora.safetensors\",\n",
    "    adapter_name=\"name\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129b8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Your prompt. \\\n",
    "If a trigger word is present in the safetensors metadata of the checkpoint, \\\n",
    "it will be added automatically, so you should omit it from your input.\"\n",
    "out = pipe(prompt,)\n",
    "out[0].resize((368,368))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7600c266",
   "metadata": {},
   "source": [
    "You can learn more about how to switch to another LoRa or disable all LoRas in `examples/inference_examples_t2v_lora.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4d40d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kandinsky-cuda12.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
